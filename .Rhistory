Gate.location=c(4,2,1,2),Food.and.drink=c(2,3,5,1),
Online.boarding=c(5,1,4,2),
Seat.comfort=c(5,2,3,5),Inflight.entertainment=c(4,3,4,3),
On.board.service=c(5,4,5,5),
Leg.room.service=c(4,5,1,1),Baggage.handling=c(3,5,2,2),
Checkin.service=c(2,3,4,1),Inflight.service=c(3,5,5,2),
Cleanliness=c(2,3,5,4))
data$Class[1]
data$Class[1,1]
data$Type.of.Travel[1,1]
data$Type.of.Travel[1]
data$satisfaction[1]
data$satisfaction[2]
dt= data.frame(Inflight.wifi.service=c(1,2,4,5),
Departure.Arrival.time.convenient=c(5,2,1,3),
Ease.of.Online.booking=c(3,3,1,2),
Gate.location=c(4,2,1,2),Food.and.drink=c(2,3,5,1),
Online.boarding=c(5,1,4,2),
Seat.comfort=c(5,2,3,5),Inflight.entertainment=c(4,3,4,3),
On.board.service=c(5,4,5,5),
Leg.room.service=c(4,5,1,1),Baggage.handling=c(3,5,2,2),
Checkin.service=c(2,3,4,1),Inflight.service=c(3,5,5,2),
Cleanliness=c(2,3,5,4),Class = c('Business','Business',
'Business','Business'),
Type.of.Travel= c('Personal Travel','Personal Travel',
'Personal Travel','Personal Travel'),
satisfaction = c('satisfied','satisfied',
'satisfied','satisfied'))
dt[4,1:14]= c(1,2,3,4,5,6,7,8,9,10,11,12,13,14)
dt = as.data.frame(predict(ds.fa3,dt[1:14]))
dt= data.frame(Inflight.wifi.service=c(1,2,4,5),
Departure.Arrival.time.convenient=c(5,2,1,3),
Ease.of.Online.booking=c(3,3,1,2),
Gate.location=c(4,2,1,2),Food.and.drink=c(2,3,5,1),
Online.boarding=c(5,1,4,2),
Seat.comfort=c(5,2,3,5),Inflight.entertainment=c(4,3,4,3),
On.board.service=c(5,4,5,5),
Leg.room.service=c(4,5,1,1),Baggage.handling=c(3,5,2,2),
Checkin.service=c(2,3,4,1),Inflight.service=c(3,5,5,2),
Cleanliness=c(2,3,5,4),Class = c('Business','Business',
'Business','Business'),
Type.of.Travel= c('Personal Travel','Personal Travel',
'Personal Travel','Personal Travel'),
satisfaction = c('satisfied','satisfied',
'satisfied','satisfied'))
dt[4,1:14]= c(1,2,3,4,5,6,7,8,9,10,11,12,13,14)
dt1 = as.data.frame(predict(ds.fa3,dt[1:14]))
names(dt1) = c("comfort","service","Convenience","boarding")
dt2 = cbind(dt[,1])
View(dt2)
dt2 = cbind(dt['boarding'])
dt2 = cbind(dt1['boarding'])
View(dt2)
dt2 = cbind(dt1['boarding'],dt['Class'],dt1['service'],dt1['comfort'],
dt[Type.of.Travel],dt1['Convenience'],dt[satisfaction])
dt2 = cbind(dt1['boarding'],dt['Class'],dt1['service'],dt1['comfort'],
dt['Type.of.Travel'],dt1['Convenience'],dt[satisfaction])
dt2 = cbind(dt1['boarding'],dt['Class'],dt1['service'],dt1['comfort'],
dt['Type.of.Travel'],dt1['Convenience'],dt['satisfaction'])
predict(rf,dt2[4,])
dt2['Class'] = as.factor(dt2['Class'])
dt2['Class'] = as.factor(dt2$Class)
predict(rf,dt2[4,])
predict(rf,dt2)
dt2['satisfaction'] = as.factor(dt2$satisfaction)
predict(rf,dt2)
View(dt2)
dt= data.frame(Inflight.wifi.service=c(1,2,4,5),
Departure.Arrival.time.convenient=c(5,2,1,3),
Ease.of.Online.booking=c(3,3,1,2),
Gate.location=c(4,2,1,2),Food.and.drink=c(2,3,5,1),
Online.boarding=c(5,1,4,2),
Seat.comfort=c(5,2,3,5),Inflight.entertainment=c(4,3,4,3),
On.board.service=c(5,4,5,5),
Leg.room.service=c(4,5,1,1),Baggage.handling=c(3,5,2,2),
Checkin.service=c(2,3,4,1),Inflight.service=c(3,5,5,2),
Cleanliness=c(2,3,5,4),Class = c('Business','Business',
'Business','Business'),
Type.of.Travel= c('Personal Travel','Personal Travel',
'Personal Travel','Personal Travel'),
satisfaction = c('satisfied','satisfied',
'satisfied','satisfied'))
dt
dt[4,1:14]= c(1,2,3,4,5,6,7,8,9,10,11,12,13,14)
dt1 = as.data.frame(predict(ds.fa3,dt[1:14]))
names(dt1) = c("comfort","service","Convenience","boarding")
dt2 = cbind(dt1['boarding'],dt['Class'],dt1['service'],dt1['comfort'],
dt['Type.of.Travel'],dt1['Convenience'],dt['satisfaction'])
View
View(dt2)
dt= data.frame(Inflight.wifi.service=c(1,2,4,5),
Departure.Arrival.time.convenient=c(5,2,1,3),
Ease.of.Online.booking=c(3,3,1,2),
Gate.location=c(4,2,1,2),Food.and.drink=c(2,3,5,1),
Online.boarding=c(5,1,4,2),
Seat.comfort=c(5,2,3,5),Inflight.entertainment=c(4,3,4,3),
On.board.service=c(5,4,5,5),
Leg.room.service=c(4,5,1,1),Baggage.handling=c(3,5,2,2),
Checkin.service=c(2,3,4,1),Inflight.service=c(3,5,5,2),
Cleanliness=c(2,3,5,4),Class = c('Business','Eco Plus',
'Eco','Business'),
Type.of.Travel= c('Personal Travel','Personal Travel',
'Personal Travel','Personal Travel'),
satisfaction = c('satisfied','satisfied',
'neutral or dissatisfied','satisfied'))
dt[4,1:14]= c(1,2,3,4,5,6,7,8,9,10,11,12,13,14)
dt1 = as.data.frame(predict(ds.fa3,dt[1:14]))
names(dt1) = c("comfort","service","Convenience","boarding")
dt2 = cbind(dt1['boarding'],dt['Class'],dt1['service'],dt1['comfort'],
dt['Type.of.Travel'],dt1['Convenience'],dt['satisfaction'])
dt2['Class'] = as.factor(dt2$Class)
dt2['satisfaction'] = as.factor(dt2$satisfaction)
predict(rf,dt2)
plumber::plumb(file='testpi.R')$run()
plumb(file='testpi.R')$run()
plumb(file='testpi.R')$run()
plumb(file='testpi.R')$run()
train <- read.csv("H:/Data analytics project 1 4th yr/train.csv")
dt = train[,3:25]
library(dplyr)
library(naniar) #summary of missing values
library(ggplot2)
library(EFA.dimensions) #polychronic correlation
library(ggcorrplot)    #correlation plot
library(caTools)  #data set split
library(psych)
library(cluster) # for gower similarity and pam
library(Rtsne) # for t-SNE plot
library(tidyr)
#make this example reproducible
set.seed(1)
#missing values summary
miss_var_summary(dt)
dt = na.omit(dt)
miss_var_summary(dt)
#duplicate values
sum(duplicated(dt))
qdt = data.frame(dt$Age,dt$Flight.Distance,dt$Departure.Delay.in.Minutes,dt$Arrival.Delay.in.Minutes)
#satisfaction bar chart
ds.eigen <- data.frame(eigen(corr_mat)$values)
colnames(ds.eigen)<-"eigen_value"
ds.eigen$type <- ifelse(ds.eigen$`eigen_value`>=1,">=1","<1")
options(repr.plot.width = 14, repr.plot.height = 8)
ggplot(ds.eigen, aes(x= reorder(rownames(ds.eigen),-`eigen_value`) ,y=`eigen_value`, fill=`type`))+
geom_col()+
labs(x="Variables", y="Eigen Value")+
scale_fill_manual(values=c("darkslategray2", "cadetblue3"))+
ylim(0,4.5)+
theme(text=element_text(size=16))
#scree plot
options(repr.plot.width = 14, repr.plot.height = 8)
scree(corr_mat)
#proportion of variability explained by 3 factors
sum(eigen(corr_mat)$values[1:3])/sum(eigen(corr_mat)$values)
#proportion of variability explained by 4 factors
sum(eigen(corr_mat)$values[1:4])/sum(eigen(corr_mat)$values)
#proportion of variability explained by 5 factors
sum(eigen(corr_mat)$values[1:6])/sum(eigen(corr_mat)$values)
#4 factors is selected
# No rotation
ds.fa1 <- fa(corr_mat, 4,rotate= "none")
ds.fa1
fa.diagram(ds.fa1)
# Orthogonal (varimax) rotation
options(repr.plot.width = 1, repr.plot.height = 2,repr.plot.res = 100)
ds.fa3 <- fa(corr_mat, 4, rotate = "varimax",fm="pa")
ds.fa3
fa.diagram(ds.fa3)
#save decision tree model
# creating correlation matrix
corr_mat = round(POLYCHORIC_R(dt[,7:20]),2)
ggcorrplot(corr_mat, hc.order = TRUE, type = "lower",
outline.col = "white",lab = TRUE)
#correlation among quantitative data
corr <- round(cor(qdt), 2)
ggcorrplot(corr, hc.order = TRUE, type = "lower",lab = TRUE)
#likert scale data
KMO(corr_mat) #kmo test
cortest.bartlett(corr_mat)
#factor analysis using eigen values
ds.eigen <- data.frame(eigen(corr_mat)$values)
colnames(ds.eigen)<-"eigen_value"
ds.eigen$type <- ifelse(ds.eigen$`eigen_value`>=1,">=1","<1")
options(repr.plot.width = 14, repr.plot.height = 8)
ggplot(ds.eigen, aes(x= reorder(rownames(ds.eigen),-`eigen_value`) ,y=`eigen_value`, fill=`type`))+
geom_col()+
labs(x="Variables", y="Eigen Value")+
scale_fill_manual(values=c("darkslategray2", "cadetblue3"))+
ylim(0,4.5)+
theme(text=element_text(size=16))
#scree plot
options(repr.plot.width = 14, repr.plot.height = 8)
scree(corr_mat)
#proportion of variability explained by 3 factors
sum(eigen(corr_mat)$values[1:3])/sum(eigen(corr_mat)$values)
#proportion of variability explained by 4 factors
sum(eigen(corr_mat)$values[1:4])/sum(eigen(corr_mat)$values)
#proportion of variability explained by 5 factors
sum(eigen(corr_mat)$values[1:6])/sum(eigen(corr_mat)$values)
#4 factors is selected
# No rotation
ds.fa1 <- fa(corr_mat, 4,rotate= "none")
ds.fa1
fa.diagram(ds.fa1)
# Orthogonal (varimax) rotation
options(repr.plot.width = 1, repr.plot.height = 2,repr.plot.res = 100)
ds.fa3 <- fa(corr_mat, 4, rotate = "varimax",fm="pa")
ds.fa3
fa.diagram(ds.fa3)
#save decision tree model
library(e1071)
c(e1071)
MODEL_SAVE_PATH = 'D:/advance analysis'
DEP_LIBS = c("e1071")
model_rds_path = paste(MODEL_SAVE_PATH, ".rds",sep='')
model_dep_path = paste(MODEL_SAVE_PATH, ".dep",sep='')
# save model
dir.create(dirname(model_path), showWarnings=FALSE, recursive=TRUE)
# save model
dir.create(dirname('D:/advance analysis'), showWarnings=FALSE, recursive=TRUE)
saveRDS(model, model_rds_path)
saveRDS(ds.fa3, model_rds_path)
saveRDS(ds.fa3, file = "D:/Data analysis/factor.rda")
saveRDS(ds.fa3, file = "D:/advance analysis/factor.rda")
MODEL_SAVE_PATH = 'D:/advance analysis/ds.fa3'
model_rds_path = paste(MODEL_SAVE_PATH, ".rds",sep='')
model_dep_path = paste(MODEL_SAVE_PATH, ".dep",sep='')
# save model
dir.create(dirname('D:/advance analysis'), showWarnings=FALSE, recursive=TRUE)
saveRDS(ds.fa3, model_rds_path)
file_conn <- file(model_dep_path)
writeLines(DEP_LIBS, file_conn)
close(file_conn)
model = ds.fa3
model_rds_path = paste(MODEL_SAVE_PATH, ".rds",sep='')
model_dep_path = paste(MODEL_SAVE_PATH, ".dep",sep='')
# save model
dir.create(dirname('D:/advance analysis'), showWarnings=FALSE, recursive=TRUE)
saveRDS(model, model_rds_path)
MODEL_SAVE_PATH = 'D:/RFactor/model'
DEP_LIBS = c("e1071")
model_rds_path = paste(MODEL_SAVE_PATH, ".rds",sep='')
model_dep_path = paste(MODEL_SAVE_PATH, ".dep",sep='')
# save model
dir.create(dirname('D:/RFactor'), showWarnings=FALSE, recursive=TRUE)
saveRDS(model, model_rds_path)
file_conn <- file(model_dep_path)
(ds.fa3)
#save decision tree model
saveRDS(ds.fa3, file = "D:/advance analysis/factor.rda")
model_rds_path = paste(MODEL_SAVE_PATH, ".rds",sep='')
model_dep_path = paste(MODEL_SAVE_PATH, ".dep",sep='')
# save model
dir.create(dirname('D:/RFactor'), showWarnings=FALSE, recursive=TRUE)
saveRDS(model, model_rds_path)
file_conn <- file(model_dep_path)
writeLines(DEP_LIBS, file_conn)
(ds.fa3)
#save decision tree model
saveRDS(ds.fa3, file = "D:/advance analysis/factor.rda")
model_rds_path = paste(MODEL_SAVE_PATH, ".rds",sep='')
model_dep_path = paste(MODEL_SAVE_PATH, ".dep",sep='')
# save model
dir.create(dirname('D:/RFactor'), showWarnings=FALSE, recursive=TRUE)
saveRDS(model, model_rds_path)
file_conn <- file(model_dep_path)
writeLines(DEP_LIBS, file_conn)
plumber::plumb(file='rapi.R')$run()
gc()
plumber::plumb(file='testpi.R')$run()
plumb(file='testpi.R')$run()
plumb(file='testpi.R')$run()
plumb(file='testpi.R')$run()
plumb(file='testpi.R')$run()
plumb(file='testpi.R')$run()
plumb(file='testpi.R')$run()
plumber::plumb(file='testpi.R')$run()
plumb(file='testpi.R')$run()
plumb(file='D:/saturn/endpoints.R')$run()
plumb(file='D:/saturn/endpoints.R')$run()
plumb(file='D:/saturn/endpoints.R')$run()
plumber::pr_run(plumber::plumb("D:/saturn/endpoints.R"), port=8000, host="0.0.0.0")
plumber::pr_run(plumber::plumb("D:/saturn/endpoints.R"), port=8000, host="0.0.0.0")
#import data set
data <- read.csv("H:/Data analytics project 1 4th yr/data.csv")
#libraries
library(randomForest)
library(caTools)
library(vip)
library(caret)
library(psych)
library(naniar) #summary of missing values
library(pdp)
library(ggplot2)
#make this example reproducible
set.seed(1)
#converting character data into factors
data['Class'] = as.factor(data$Class)
data['satisfaction'] = as.factor(data$satisfaction)
#splitting data set into train and validation
#use 80% of dataset as training set and 20% as test set
sample <- sample.split(data$Age, SplitRatio = 0.8)
train  <- subset(data, sample == TRUE)
valid   <- subset(data, sample == FALSE)
#performing defualt random forest
s1= Sys.time()
rf <-randomForest(as.factor(satisfaction)~.,data=train, ntree=50)
s2=Sys.time()
rf_train_pred = predict(rf,train,type = 'class')
confusionMatrix(rf_train_pred,train$satisfaction)
rf_valid_pred = predict(rf,valid,type = 'class')
confusionMatrix(rf_valid_pred,valid$satisfaction)
#performing defualt random forest
s3= Sys.time()
rf1 <-randomForest(as.factor(satisfaction)~.,data=train, ntree=100)
s4=Sys.time()
rf1_train_pred = predict(rf1,train,type = 'class')
confusionMatrix(rf1_train_pred,train$satisfaction)
rf1_valid_pred = predict(rf1,valid,type = 'class')
confusionMatrix(rf1_valid_pred,valid$satisfaction)
View(train)
vip(rf1,geom = "point")
#import data set
data <- read.csv("H:/Data analytics project 1 4th yr/data.csv")
#libraries
library(randomForest)
library(caTools)
library(vip)
library(caret)
library(psych)
library(naniar) #summary of missing values
library(pdp)
library(ggplot2)
#make this example reproducible
set.seed(1)
#converting character data into factors
data['Class'] = as.factor(data$Class)
data['satisfaction'] = as.factor(data$satisfaction)
#splitting data set into train and validation
#use 80% of dataset as training set and 20% as test set
sample <- sample.split(data$Age, SplitRatio = 0.8)
train  <- subset(data, sample == TRUE)
valid   <- subset(data, sample == FALSE)
#performing defualt random forest
s1= Sys.time()
rf <-randomForest(as.factor(satisfaction)~.,data=train, ntree=50)
s2=Sys.time()
rf_train_pred = predict(rf,train,type = 'class')
confusionMatrix(rf_train_pred,train$satisfaction)
rf_valid_pred = predict(rf,valid,type = 'class')
confusionMatrix(rf_valid_pred,valid$satisfaction)
#performing defualt random forest
s3= Sys.time()
rf1 <-randomForest(as.factor(satisfaction)~.,data=train, ntree=100)
s4=Sys.time()
rf1_train_pred = predict(rf1,train,type = 'class')
confusionMatrix(rf1_train_pred,train$satisfaction)
rf1_valid_pred = predict(rf1,valid,type = 'class')
confusionMatrix(rf1_valid_pred,valid$satisfaction)
View(train)
vip(rf1,geom = "point")
sd(train$boarding)
#######################################################################
#try to fit random forest with less variables
nw_train = train[c('boarding','Class','service','comfort',
'Type.of.Travel','Convenience','satisfaction')]
nw_valid = valid[c('boarding','Class','service','comfort',
'Type.of.Travel','Convenience','satisfaction')]
nw_rf <-randomForest(as.factor(satisfaction)~.,data=nw_train, ntree=100
)
nw_pred = predict(nw_rf,nw_train,type = 'class')
confusionMatrix(nw_pred,nw_train$satisfaction)
nw_valid_pred = predict(nw_rf, nw_valid, type = 'class')
confusionMatrix(nw_valid_pred,nw_valid$satisfaction)
#hyperparameter tuning
tuneRF(nw_train[,-7], as.factor(nw_train[,7]), ntreeTry=100, stepFactor=0.5,
improve=0.05 )
tu_rf <-randomForest(as.factor(satisfaction)~.,data=nw_train, ntree=100
,mtry = 4 )
tu_pred = predict(tu_rf,nw_train,type = 'class')
confusionMatrix(tu_pred,nw_train$satisfaction)
tu_valid_pred = predict(tu_rf,nw_valid,type= 'class')
confusionMatrix(tu_valid_pred,nw_valid$satisfaction)
#######################################################################
#test set results
df <- read.csv("H:/Data analytics project 1 4th yr/test.csv")
dt = df[,3:25]
#missing values summary
miss_var_summary(dt)
dt = na.omit(dt)
miss_var_summary(dt)
#duplicate values
sum(duplicated(dt))
#loading factor analysis
ds.fa3=readRDS("H:/Data analytics project 1 4th yr/factor.rda")
fs <- factor.scores(dt[,7:20], ds.fa3)
fs <- fs$scores
df <- cbind(dt[,1:6],fs,dt[,21:23])
#renaming columns
names(df)[7:10] = c("comfort","service","Convenience","boarding")
df = df[c('boarding','Class','service','comfort',
'Type.of.Travel','Convenience','satisfaction')]
df['Class']= as.factor(df$Class)
df['satisfaction'] = as.factor(df$satisfaction)
tu_test_pred = predict(tu_rf,df,type = 'class')
confusionMatrix(tu_test_pred,as.factor(df$satisfaction))
str(nw_train)
write.csv(nw_train,"D:\\advance analysis\\n_train.csv", row.names = FALSE)
#variable importance plot
vip(tu_rf)
partialPlot(x=tu_rf, pred.data=df, x.var=Convenience)
partialPlot(x=tu_rf, pred.data=df, x.var=Class, which.class="satisfied")
cls_bor = partial(tu_rf,pred.var = c('comfort','Class'),chull = TRUE,
which.class = 'satisfied' )
cls_bor =autoplot(cls_bor, contour = TRUE,
legend.title = "Partial\ndependence")
grid.arrange(cls_bor)
#import data set
data <- read.csv("H:/Data analytics project 1 4th yr/data.csv")
#libraries
library(randomForest)
library(caTools)
library(vip)
library(caret)
library(psych)
library(naniar) #summary of missing values
library(pdp)
library(ggplot2)
#make this example reproducible
set.seed(1)
#converting character data into factors
data['Class'] = as.factor(data$Class)
data['satisfaction'] = as.factor(data$satisfaction)
#splitting data set into train and validation
#use 80% of dataset as training set and 20% as test set
sample <- sample.split(data$Age, SplitRatio = 0.8)
train  <- subset(data, sample == TRUE)
valid   <- subset(data, sample == FALSE)
#performing defualt random forest
s1= Sys.time()
rf <-randomForest(as.factor(satisfaction)~.,data=train, ntree=50)
s2=Sys.time()
rf_train_pred = predict(rf,train,type = 'class')
confusionMatrix(rf_train_pred,train$satisfaction)
rf_valid_pred = predict(rf,valid,type = 'class')
confusionMatrix(rf_valid_pred,valid$satisfaction)
#performing defualt random forest
s3= Sys.time()
rf1 <-randomForest(as.factor(satisfaction)~.,data=train, ntree=100)
s4=Sys.time()
rf1_train_pred = predict(rf1,train,type = 'class')
confusionMatrix(rf1_train_pred,train$satisfaction)
rf1_valid_pred = predict(rf1,valid,type = 'class')
confusionMatrix(rf1_valid_pred,valid$satisfaction)
View(train)
vip(rf1,geom = "point")
sd(train$boarding)
#######################################################################
#try to fit random forest with less variables
nw_train = train[c('boarding','Class','service','comfort',
'Type.of.Travel','Convenience','satisfaction')]
nw_valid = valid[c('boarding','Class','service','comfort',
'Type.of.Travel','Convenience','satisfaction')]
nw_rf <-randomForest(as.factor(satisfaction)~.,data=nw_train, ntree=100
)
nw_pred = predict(nw_rf,nw_train,type = 'class')
confusionMatrix(nw_pred,nw_train$satisfaction)
nw_valid_pred = predict(nw_rf, nw_valid, type = 'class')
confusionMatrix(nw_valid_pred,nw_valid$satisfaction)
#hyperparameter tuning
tuneRF(nw_train[,-7], as.factor(nw_train[,7]), ntreeTry=100, stepFactor=0.5,
improve=0.05 )
tu_rf <-randomForest(as.factor(satisfaction)~.,data=nw_train, ntree=100
,mtry = 4 )
tu_pred = predict(tu_rf,nw_train,type = 'class')
confusionMatrix(tu_pred,nw_train$satisfaction)
tu_valid_pred = predict(tu_rf,nw_valid,type= 'class')
confusionMatrix(tu_valid_pred,nw_valid$satisfaction)
#######################################################################
#test set results
df <- read.csv("H:/Data analytics project 1 4th yr/test.csv")
dt = df[,3:25]
#missing values summary
miss_var_summary(dt)
dt = na.omit(dt)
miss_var_summary(dt)
#duplicate values
sum(duplicated(dt))
#loading factor analysis
ds.fa3=readRDS("H:/Data analytics project 1 4th yr/factor.rda")
fs <- factor.scores(dt[,7:20], ds.fa3)
fs <- fs$scores
df <- cbind(dt[,1:6],fs,dt[,21:23])
#renaming columns
names(df)[7:10] = c("comfort","service","Convenience","boarding")
df = df[c('boarding','Class','service','comfort',
'Type.of.Travel','Convenience','satisfaction')]
df['Class']= as.factor(df$Class)
df['satisfaction'] = as.factor(df$satisfaction)
tu_test_pred = predict(tu_rf,df,type = 'class')
confusionMatrix(tu_test_pred,as.factor(df$satisfaction))
str(nw_train)
write.csv(nw_train,"D:\\advance analysis\\n_train.csv", row.names = FALSE)
#variable importance plot
vip(tu_rf)
partialPlot(x=tu_rf, pred.data=df, x.var=Convenience)
partialPlot(x=tu_rf, pred.data=df, x.var=Class, which.class="satisfied")
cls_bor = partial(tu_rf,pred.var = c('comfort','Class'),chull = TRUE,
which.class = 'satisfied' )
cls_bor =autoplot(cls_bor, contour = TRUE,
legend.title = "Partial\ndependence")
grid.arrange(cls_bor)
